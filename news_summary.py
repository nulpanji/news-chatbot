import streamlit as st
import feedparser
from googletrans import Translator
import datetime
import re
import yfinance as yf
import requests
import re
import yfinance as yf
import requests

# ì‹ ë¢° ì–¸ë¡ ì‚¬ RSS í”¼ë“œ (ê¸€ë¡œë²Œ + í•œêµ­)
RSS_FEEDS = {
    'êµ­ì œ': [
        'http://feeds.bbci.co.uk/news/world/rss.xml',
        'http://feeds.reuters.com/Reuters/worldNews',
        'https://apnews.com/rss',
        'https://www.yna.co.kr/rss/all.do?site=001',  # ì—°í•©ë‰´ìŠ¤ êµ­ì œ í¬í•¨
    ],
    'ê²½ì œ': [
        'https://feeds.bbci.co.uk/news/business/rss.xml',
        'http://feeds.reuters.com/reuters/businessNews',
        'https://www.bloomberg.co.kr/feed/podcast/etf-report.xml',
        'https://www.hankyung.com/feed/news',
        'https://rss.donga.com/economy.xml',
    ],
    'ì‚¬íšŒ': [
        'https://www.hani.co.kr/rss/',
        'https://rss.donga.com/society.xml',
        'https://www.chosun.com/arc/outboundfeeds/rss/category/national/?outputType=xml',
    ],
    'ìŠ¤í¬ì¸ ': [
        'http://www.yonhapnewstv.co.kr/browse/feed/14',
        'https://www.chosun.com/arc/outboundfeeds/rss/category/sports/?outputType=xml',
        'https://sports.news.naver.com/rss/index.nhn',
    ]
}

translator = Translator()

# HOT ë‰´ìŠ¤ í‚¤ì›Œë“œ í™•ì¥ (ê²½ì œ/í…Œí¬ í¬í•¨)
HOT_NEWS_KEYWORDS = [
    "ì „ìŸ", "ì§€ì§„", "íƒœí’", "ì“°ë‚˜ë¯¸", "í­ë°œ", "ê¸´ê¸‰", "ì†ë³´", "breaking", "alert", "emergency", "disaster", "ì „íˆ¬", "ê³µìŠµ", "í­ìš°", "í™ìˆ˜",
    "í…ŒìŠ¬ë¼", "tesla", "ì—”ë¹„ë””ì•„", "nvidia", "ì½”ì¸", "ë¹„íŠ¸ì½”ì¸", "bitcoin", "ì´ë”ë¦¬ì›€", "ethereum", "xrp", "ë¦¬í”Œ", "ì£¼ì‹", "í™˜ìœ¨", "ê¸ˆë¦¬", "ì¦ì‹œ", "stock", "market", "fed", "ì—°ì¤€"
]

# ì‹¤ì‹œê°„ HOT ë‰´ìŠ¤ ì¶”ì¶œ
def fetch_hot_news():
    articles = []
    now = datetime.datetime.utcnow()
    two_days_ago = now - datetime.timedelta(days=2)
    for cat in RSS_FEEDS:
        for url in RSS_FEEDS[cat]:
            feed = feedparser.parse(url)
            for entry in feed.entries:
                pub_date = None
                for date_key in ['published_parsed', 'updated_parsed']:
                    if date_key in entry and entry[date_key]:
                        pub_date = datetime.datetime(*entry[date_key][:6])
                        break
                if not pub_date or pub_date < two_days_ago:
                    continue
                title = entry.title
                if 'content' in entry and entry.content:
                    summary = entry.content[0].value
                elif 'summary' in entry:
                    summary = entry.summary
                else:
                    summary = ''
                texts = [title, summary]
                found = False
                for kw in HOT_NEWS_KEYWORDS:
                    for txt in texts:
                        if re.search(kw, txt, re.IGNORECASE):
                            found = True
                            break
                    if found:
                        break
                if not found:
                    continue
                articles.append({
                    'title': title,
                    'summary': summary,
                    'link': entry.link,
                    'source': feed.feed.title if 'title' in feed.feed else url,
                    'pub_date': pub_date
                })
    articles.sort(key=lambda x: x['pub_date'], reverse=True)
    return articles[:10]  # ìƒìœ„ 10ê±´ë§Œ

# ì‹¤ì‹œê°„ ì£¼ì‹ ì‹œì„¸ (Yahoo Finance)
def fetch_stock_price(symbol):
    try:
        ticker = yf.Ticker(symbol)
        data = ticker.history(period="1d")
        if not data.empty:
            price = data['Close'].iloc[-1]
            return f"{price:,.2f}"
        else:
            return "N/A"
    except Exception:
        return "N/A"

# ì‹¤ì‹œê°„ ì½”ì¸ ì‹œì„¸ (CoinGecko)
def fetch_crypto_price(symbol):
    try:
        url = f"https://api.coingecko.com/api/v3/simple/price?ids={symbol}&vs_currencies=krw,usd"
        res = requests.get(url, timeout=5)
        data = res.json()
        price_krw = data[symbol]['krw']
        price_usd = data[symbol]['usd']
        return f"â‚©{price_krw:,} / ${price_usd:,}"
    except Exception:
        return "N/A"

# ì‹¤ì‹œê°„ í™˜ìœ¨ (USD/KRW, EUR/KRW, Yahoo Finance)
def fetch_fx_rate(pair):
    try:
        ticker = yf.Ticker(pair)
        data = ticker.history(period="1d")
        if not data.empty:
            rate = data['Close'].iloc[-1]
            return f"{rate:,.2f}"
        else:
            return "N/A"
    except Exception:
        return "N/A"

# ì‹¤ì‹œê°„ ë‚ ì”¨ (OpenWeatherMap)
OPENWEATHER_API_KEY = "b28b5663f60a009761ddeb6059a824fe"
def fetch_weather(city="Seoul"):
    try:
        url = f"https://api.openweathermap.org/data/2.5/weather?q={city}&appid={OPENWEATHER_API_KEY}&units=metric&lang=kr"
        res = requests.get(url, timeout=5)
        data = res.json()
        temp = data['main']['temp']
        desc = data['weather'][0]['description']
        return f"{city}: {temp}Â°C, {desc}"
    except Exception:
        return f"{city}: N/A"

def fetch_and_translate_news(keyword=None, translate_to_ko=False):
    articles = []
    now = datetime.datetime.utcnow()
    one_month_ago = now - datetime.timedelta(days=31)
    all_feeds = sum(RSS_FEEDS.values(), [])
    for url in all_feeds:
        feed = feedparser.parse(url)
        for entry in feed.entries:
            # ë‚ ì§œ íŒŒì‹±
            pub_date = None
            for date_key in ['published_parsed', 'updated_parsed']:
                if date_key in entry and entry[date_key]:
                    pub_date = datetime.datetime(*entry[date_key][:6])
                    break
            if not pub_date:
                continue
            # í•œ ë‹¬ ì´ë‚´ë§Œ
            if pub_date < one_month_ago:
                continue
            title = entry.title
            # content ìš°ì„ , ì—†ìœ¼ë©´ summary
            if 'content' in entry and entry.content:
                summary = entry.content[0].value
            elif 'summary' in entry:
                summary = entry.summary
            else:
                summary = ''
            link = entry.link
            is_korean_news = any(domain in url for domain in [
                'yna.co.kr', 'hani.co.kr', 'donga.com', 'chosun.com', 'naver.com', 'hankyung.com'
            ])
            if translate_to_ko or not is_korean_news:
                try:
                    title_ko = translator.translate(title, dest='ko').text if not is_korean_news else title
                except Exception:
                    title_ko = title
                try:
                    summary_ko = translator.translate(summary, dest='ko').text if summary and not is_korean_news else summary
                except Exception:
                    summary_ko = summary
            else:
                title_ko = title
                summary_ko = summary
            # í‚¤ì›Œë“œ í•„í„° (ì›ë¬¸+ë²ˆì—­ ëª¨ë‘ í¬í•¨)
            if keyword:
                keyword_lower = keyword.lower()
                if (keyword_lower not in title.lower() and
                    keyword_lower not in summary.lower() and
                    keyword_lower not in title_ko.lower() and
                    keyword_lower not in summary_ko.lower()):
                    continue
            articles.append({
                'title': title_ko,
                'summary': summary_ko,
                'link': link,
                'source': feed.feed.title if 'title' in feed.feed else url,
                'pub_date': pub_date
            })
    # ìµœì‹ ìˆœ ì •ë ¬ (ë§¨ ìœ„ê°€ ìµœì‹ )
    articles.sort(key=lambda x: x['pub_date'], reverse=True)
    return articles

# Streamlit ì›¹ì±—ë´‡ UI
# ---- UI ----
st.set_page_config(page_title="ì‹¤ì‹œê°„ ë‰´ìŠ¤ ì±—ë´‡", layout="wide")
st.markdown("""
<style>
    .main {max-width: 700px; margin: auto;}
    @media (max-width: 600px) {
        .main {max-width: 100vw; padding: 0 8px;}
    }
</style>
<div class="main">
""", unsafe_allow_html=True)

st.title("ğŸŒ ì‹¤ì‹œê°„ ë‰´ìŠ¤ ì±—ë´‡")
st.write("ì¹´í…Œê³ ë¦¬ì™€(ì„ íƒ) í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ë©´ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ í•œêµ­ì–´ ë˜ëŠ” ì›ë³¸ìœ¼ë¡œ ìš”ì•½í•´ ë“œë¦½ë‹ˆë‹¤.")

# --- HOT ë‰´ìŠ¤, ì‹œì„¸, í™˜ìœ¨, ë‚ ì”¨ ìœ„ì ¯ ---
hot_news = fetch_hot_news()
with st.expander("ğŸ”¥ ì‹¤ì‹œê°„ ì†ë³´/Hot News (ìµœê·¼ 2ì¼)", expanded=True):
    if not hot_news:
        st.info("ìµœê·¼ 2ì¼ ì´ë‚´ ì†ë³´/í•«ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for i, art in enumerate(hot_news, 1):
            st.markdown(f"**{i}. [{art['title']}]({art['link']})**")
            if art['summary']:
                st.write(f"ìš”ì•½: {art['summary']}")
            st.caption(f"ì¶œì²˜: {art['source']} | ë‚ ì§œ: {art['pub_date'].strftime('%Y-%m-%d %H:%M')}")
            st.write("---")

st.subheader(":chart_with_upwards_trend: ì‹¤ì‹œê°„ ì‹œì„¸/í™˜ìœ¨/ë‚ ì”¨")
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("í…ŒìŠ¬ë¼(TSLA)", fetch_stock_price("TSLA"))
    st.metric("ì—”ë¹„ë””ì•„(NVDA)", fetch_stock_price("NVDA"))
with col2:
    st.metric("ì‚¼ì„±ì „ì(005930.KS)", fetch_stock_price("005930.KS"))
    st.metric("ë¹„íŠ¸ì½”ì¸(BTC)", fetch_crypto_price("bitcoin"))
with col3:
    st.metric("ì´ë”ë¦¬ì›€(ETH)", fetch_crypto_price("ethereum"))
    st.metric("XRP", fetch_crypto_price("ripple"))
with col4:
    st.metric("USD/KRW", fetch_fx_rate("USDKRW=X"))
    st.metric("EUR/KRW", fetch_fx_rate("EURKRW=X"))
    st.metric("ì„œìš¸ ë‚ ì”¨", fetch_weather("Seoul"))

# ---- ë‰´ìŠ¤ ê²€ìƒ‰ UI ----
keyword = st.text_input("í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ê²€ìƒ‰ (ì¹´í…Œê³ ë¦¬ êµ¬ë¶„ ì—†ìŒ)", "")
lang_option = st.radio("ê¸°ì‚¬ ì–¸ì–´ ì„ íƒ", ["ì›ë³¸(ì˜ì–´/í•œêµ­ì–´)", "ëª¨ë“  ê¸°ì‚¬ í•œêµ­ì–´ë¡œ ë²ˆì—­"], horizontal=True)
translate_to_ko = lang_option == "ëª¨ë“  ê¸°ì‚¬ í•œêµ­ì–´ë¡œ ë²ˆì—­"

if st.button("ë‰´ìŠ¤ ì°¾ê¸°"):
    with st.spinner("ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        articles = fetch_and_translate_news(keyword.strip(), translate_to_ko=translate_to_ko)
    if not articles:
        st.warning("ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for i, art in enumerate(articles, 1):
            st.markdown(f"**{i}. [{art['title']}]({art['link']})**")
            if art['summary']:
                st.write(f"ìš”ì•½: {art['summary']}")
            st.caption(f"ì¶œì²˜: {art['source']} | ë‚ ì§œ: {art['pub_date'].strftime('%Y-%m-%d %H:%M')}")
            st.write("---")

st.markdown("</div>", unsafe_allow_html=True)

# ---- ë„ë©”ì¸ ì£¼ì†Œ ìœ ì§€ ì•ˆë‚´ ----
# ê°€ë¹„ì•„ í”„ë ˆì„ í¬ì›Œë”© ì‚¬ìš© ì‹œ ì£¼ì†Œì°½ì— www.nulpanji.com ìœ ì§€ ê°€ëŠ¥(ë‹¨, ì¼ë¶€ ë¸Œë¼ìš°ì €ì—ì„œ ì°¨ë‹¨ë  ìˆ˜ ìˆìŒ)
# ì™„ë²½í•œ ì»¤ìŠ¤í…€ ë„ë©”ì¸ ì—°ê²°ì„ ì›í•˜ë©´ Netlify/Vercel ë“±ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìš”
