import streamlit as st
import requests
from deep_translator import GoogleTranslator
import datetime
import os

def fetch_hot_news():
    print("[DEBUG] ðŸ”„ fetch_hot_news() ì‹œìž‘ë¨")
    NEWSAPI_KEY = os.getenv("NEWSAPI_KEY")
    print(f"[DEBUG] NEWSAPI_KEY: {NEWSAPI_KEY}")
    countries = ['us', 'kr', 'jp']
    all_articles = []

    # 1. êµ­ê°€ë³„ í—¤ë“œë¼ì¸ (Top Headlines)
    for country in countries:
        url = "https://newsapi.org/v2/top-headlines"
        params = {
            "country": country,
            "pageSize": 3,
            "apiKey": NEWSAPI_KEY
        }
        try:
            res = requests.get(url, params=params, timeout=10)
            data = res.json()
            print(f"[DEBUG] {country} API ì‘ë‹µ: {data}")
            if data.get("status") == "ok":
                articles = data.get("articles", [])
                print(f"[{country.upper()} í—¤ë“œë¼ì¸] {len(articles)}ê°œ ê¸°ì‚¬ ê°€ì ¸ì˜´")
                for art in articles:
                    title = art.get("title", "")
                    summary = art.get("description", "")
                    link = art.get("url", "")
                    source = art.get("source", {}).get("name", "")
                    pub_date = art.get("publishedAt", "")[:16].replace("T", " ")
                    all_articles.append({
                        "title": title,
                        "summary": summary,
                        "link": link,
                        "source": source,
                        "pub_date": pub_date,
                        "country": country.upper(),
                        "type": "headline"
                    })
        except Exception as e:
            print(f"[{country}] ì˜¤ë¥˜: {e}")

    print(f"[DEBUG] ðŸŒ ìˆ˜ì§‘ëœ ì „ì²´ ê¸°ì‚¬ ìˆ˜ (ì¤‘ë³µ í¬í•¨): {len(all_articles)}")

    # 2. ì¸ê¸° ì£¼ì œ ê¸°ë°˜ Everything ê²€ìƒ‰
    url = "https://newsapi.org/v2/everything"
    from_date = (datetime.datetime.now(datetime.timezone.utc) - datetime.timedelta(days=3)).strftime("%Y-%m-%d")
    topics = [
        "global economy", "international politics", "technology innovation"
    ]
    for topic in topics:
        params = {
            "q": topic,
            "from": from_date,
            "sortBy": "popularity",
            "language": "en",
            "pageSize": 2,
            "apiKey": NEWSAPI_KEY
        }
        try:
            res = requests.get(url, params=params, timeout=10)
            data = res.json()
            print(f"[DEBUG] {topic} API ì‘ë‹µ: {data}")
            if data.get("status") == "ok":
                articles = data.get("articles", [])
                print(f"[{topic}] {len(articles)}ê°œ ì¸ê¸° ê¸°ì‚¬ ê°€ì ¸ì˜´")
                for art in articles:
                    title = art.get("title", "")
                    summary = art.get("description", "")
                    link = art.get("url", "")
                    source = art.get("source", {}).get("name", "")
                    pub_date = art.get("publishedAt", "")[:16].replace("T", " ")
                    all_articles.append({
                        "title": title,
                        "summary": summary,
                        "link": link,
                        "source": source,
                        "pub_date": pub_date,
                        "topic": topic,
                        "type": "popular"
                    })
        except Exception as e:
            print(f"[{topic}] ì˜¤ë¥˜: {e}")

    # 3. ì¤‘ë³µ ì œê±°
    seen_titles = set()
    unique_articles = []
    for article in all_articles:
        title = (article.get("title") or "").lower().strip()
        if title and title not in seen_titles:
            seen_titles.add(title)
            unique_articles.append(article)

    print(f"[DEBUG] âœ… ì¤‘ë³µ ì œê±° í›„ ê¸°ì‚¬ ìˆ˜: {len(unique_articles)}")

    # 4. ìµœì‹ ìˆœ ì •ë ¬
    headlines = [a for a in unique_articles if a.get("type") == "headline"]
    populars = [a for a in unique_articles if a.get("type") == "popular"]
    headlines.sort(key=lambda x: x["pub_date"], reverse=True)
    populars.sort(key=lambda x: x["pub_date"], reverse=True)

    return (headlines + populars)[:30]

# --- Streamlit UI ---
# Render í˜¸í™˜: PORT í™˜ê²½ë³€ìˆ˜ë¡œ í¬íŠ¸ ë°”ì¸ë”© (í•„ìˆ˜)
if "PORT" in os.environ:
    import sys
    port = int(os.environ["PORT"])
    sys.argv += ["run", sys.argv[0], "--server.port", str(port)]

st.set_page_config(page_title="ðŸŒ ê¸€ë¡œë²Œ ë‰´ìŠ¤ ë¦¬ë”", layout="wide")
st.title("ðŸŒ ê¸€ë¡œë²Œ í•«ë‰´ìŠ¤ ë¦¬ë”")
st.write("ì§€ë‚œ 7ì¼ê°„ ì„¸ê³„ì ìœ¼ë¡œ ê°€ìž¥ ì¸ê¸°ìžˆëŠ” ë‰´ìŠ¤ 30ê°œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")

lang_option = st.radio("ê¸°ì‚¬ ì–¸ì–´ ì„ íƒ", ["ì˜ì–´ ì›ë³¸", "í•œêµ­ì–´ ë²ˆì—­"], horizontal=True)
translate_to_ko = lang_option == "í•œêµ­ì–´ ë²ˆì—­"

news_list = fetch_hot_news()

if not news_list:
    # ë”ë¯¸ ë°ì´í„°ë¡œ UI ì •ìƒ ë™ìž‘ í™•ì¸
    news_list = [{
        "title": "Streamlit ì•±ì€ ì •ìƒ ìž‘ë™ ì¤‘ìž…ë‹ˆë‹¤!",
        "summary": "APIì—ì„œ ë‰´ìŠ¤ê°€ ì˜¤ì§€ ì•Šì„ ë•Œ ì´ ë¬¸êµ¬ê°€ ëœ¹ë‹ˆë‹¤.",
        "link": "https://newsapi.org",
        "source": "NewsAPI í…ŒìŠ¤íŠ¸",
        "pub_date": "2025-05-13"
    }]

for i, art in enumerate(news_list, 1):
    title = art['title']
    summary = art['summary']
    if translate_to_ko:
        try:
            title = GoogleTranslator(source='auto', target='ko').translate(title) if title else title
        except Exception:
            pass
        try:
            summary = GoogleTranslator(source='auto', target='ko').translate(summary) if summary else summary
        except Exception:
            pass
    st.markdown(f"**{i}. [{title}]({art['link']})**")
    if summary:
        st.write(summary[:150] + ("..." if len(summary) > 150 else ""))
    st.caption(f"{art.get('source', '')} | {art.get('pub_date', '')}")